{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "giusto per capirci, quello che poi va usato nel notebook ufficiale è quello contenuto in text_enrichment.py\n",
    "che fa tutto ilnecessario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "angolo del text enrichment, qua non si babbia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "wd = '/'.join(os.getcwd().split('/')[:-1])\n",
    "sys.path.append(wd)\n",
    "\n",
    "random_state=69\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import set_seeds, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iro</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Intanto la partita per Via Nazionale si compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False illusioni, sgradevoli realtà Mario Monti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>False illusioni, sgradevoli realtà #editoriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>Anche prodotti alimentari tipici pugliesi in v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>intensità di vita  https://t.co/jv4aARxzhz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>Oggi tutti che iniziano l'università e io sul ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>@GliIntoccabili @nonleggerlo Ma Ferrero? il co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>Non vedi l'ora che venga qui, almeno lo sentir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9410 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iro                                               text\n",
       "0       0  Intanto la partita per Via Nazionale si compli...\n",
       "1       0  False illusioni, sgradevoli realtà Mario Monti...\n",
       "2       0  False illusioni, sgradevoli realtà #editoriale...\n",
       "3       0  Mario Monti: Berlusconi risparmi all'Italia il...\n",
       "4       0  Mario Monti: Berlusconi risparmi all'Italia il...\n",
       "...   ...                                                ...\n",
       "1995    0  Anche prodotti alimentari tipici pugliesi in v...\n",
       "1996    0         intensità di vita  https://t.co/jv4aARxzhz\n",
       "1997    0  Oggi tutti che iniziano l'università e io sul ...\n",
       "1998    0  @GliIntoccabili @nonleggerlo Ma Ferrero? il co...\n",
       "1999    0  Non vedi l'ora che venga qui, almeno lo sentir...\n",
       "\n",
       "[9410 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['iro', 'text']\n",
    "\n",
    "df1 = pd.read_csv(wd + \"/data/training_set_sentipolc16.csv\", sep=\",\")\n",
    "\n",
    "# stesse colonne, lultima colonna è il topic (non è binaria)\n",
    "df2 = pd.read_csv(wd + \"/data/test_set_sentipolc16_gold2000.csv\", sep=\",\",names=list(df1.columns))\n",
    "\n",
    "df1 = pd.concat([df1, df2])[cols]\n",
    "df = df1.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['text'].apply(lambda x : 'monti?!' in x.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_enrichment import create_occurrences_dict\n",
    "\n",
    "df['list'] = df['text'].apply(lambda x : x.split())\n",
    "\n",
    "dizionario = create_occurrences_dict(df, colname='list')\n",
    "\n",
    "# chiavi = set(dizionario[1].keys()).intersection(set(dizionario[0].keys()))\n",
    "\n",
    "# differenze = {\n",
    "#     key: (dizionario[1][key], dizionario[0][key], dizionario[1][key] - dizionario[0][key])\n",
    "#     for key in chiavi\n",
    "# }\n",
    "\n",
    "# dizionario_ordinato = dict(sorted(differenze.items(), key=lambda x: x[1][2], reverse=True))\n",
    "\n",
    "# for key, (val1, val2, diff) in dizionario_ordinato.items():\n",
    "#     print(f'{key}\\t\\ttrue {val1}, false {val2}, differenza {diff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dizionario_ordinato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parole_false_ordinato = sorted(dizionario[0].items(), key=lambda x: x[1], reverse=True)\n",
    "# parole_vere_ordinato = sorted(dizionario[0].items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from text_enrichment import get_prob_from_sentence\n",
    "\n",
    "# get_prob_from_sentence('suca #mannaggi haha', features_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9410, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_set, val_set = train_test_split(df,\n",
    "#                                      test_size=0.3,\n",
    "#                                      shuffle=True,\n",
    "#                                      random_state=random_state\n",
    "#                     )\n",
    "train_set = df\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrai_hastag(testo): return [hashtag.lstrip('#') for hashtag in re.findall(r'#\\w+', testo)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i link non contengono nessuna informazione.\n",
    "# in modo che vengano trattati come hastag \n",
    "\n",
    "link_as_hastag = False\n",
    "if link_as_hastag:\n",
    "    train_set['text'] = train_set['text'].apply(lambda x: re.sub(r'https?v?:\\/\\/\\S+', '#LINK', x))\n",
    "else:\n",
    "    train_set['text'] = train_set['text'].apply(lambda x: re.sub(r'https?v?:\\/\\/\\S+', '', x))\n",
    "train_set['text'] = train_set['text'].apply(lambda x: re.sub(r'\\b(?:ha|he|hi|ho|ah|eh|ih|oh|uh){2,}\\b', '#RISATA', x))\n",
    "train_set['hastags'] = train_set['text'].apply(estrai_hastag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "levo tutti i tweet che non contengono info utili (hastag, risate, link )<br>\n",
    "training_set_sentipolc16.csv<br>\n",
    "&emsp; 1700(non iro) + 315(iro) =  2015 (tweet senza hastag)<br>\n",
    "l'altro dataset mi sembra inutilizzabile idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iro</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Saccomanni, Monti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[editoriale, rassegna]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[mariomontipremier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>[ottoemezzo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>[la7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>0</td>\n",
       "      <td>[modenafc1912]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0</td>\n",
       "      <td>[Piacenza, OroRosso]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0</td>\n",
       "      <td>[WeWillMeetAgain1D]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0</td>\n",
       "      <td>[39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0</td>\n",
       "      <td>[rifugiati, clandestini]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4179 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iro                   hastags\n",
       "0       0       [Saccomanni, Monti]\n",
       "2       0    [editoriale, rassegna]\n",
       "3       0       [mariomontipremier]\n",
       "14      0              [ottoemezzo]\n",
       "15      1                     [la7]\n",
       "...   ...                       ...\n",
       "1979    0            [modenafc1912]\n",
       "1984    0      [Piacenza, OroRosso]\n",
       "1989    0       [WeWillMeetAgain1D]\n",
       "1990    0                      [39]\n",
       "1993    0  [rifugiati, clandestini]\n",
       "\n",
       "[4179 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df_hasth = train_set[['iro','hastags']].copy()\n",
    "tmp_df_hasth = tmp_df_hasth[tmp_df_hasth['hastags'].apply(lambda x: len(x) > 0)]\n",
    "tmp_df_hasth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h5>QUESTO CODICE NON TIENE CONTO DELLE CO-OCCORRENZE</h5>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_dict = {0: {}, 1:{}}\n",
    "for iro, elems  in tmp_df_hasth.values:\n",
    "    for elem in elems:\n",
    "        if elem.lower() in tmd_dict[iro]:\n",
    "            tmd_dict[iro][elem.lower()] += 1\n",
    "        else:\n",
    "            tmd_dict[iro][elem.lower()] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(grillo              |iro=0)\t= 0.1366\n",
      "P(labuonascuola       |iro=0)\t= 0.1262\n",
      "P(monti               |iro=0)\t= 0.0945\n",
      "P(governo             |iro=0)\t= 0.0276\n",
      "P(serviziopubblico    |iro=0)\t= 0.0172\n",
      "P(piazzapulita        |iro=0)\t= 0.0131\n",
      "P(m5s                 |iro=0)\t= 0.0129\n",
      "P(scuola              |iro=0)\t= 0.0114\n",
      "P(risata              |iro=0)\t= 0.0107\n"
     ]
    }
   ],
   "source": [
    "# sorted_hashtags = sorted(tmd_dict[0].items(), key=lambda x: x[1], reverse=True)\n",
    "tot_n_iro = sum(tmd_dict[0].values()) # somma di tutti gli hastag contenuti in tweets non ironici\n",
    "n_top_tweet = 15\n",
    "prob_thr = 0.01\n",
    "\n",
    "relevant_tweets = set()\n",
    "p_hastg_non_iro = {}\n",
    "\n",
    "for _, elem in enumerate(sorted(tmd_dict[0].items(), key=lambda x: x[1], reverse=True)):\n",
    "    if (elem[1]/tot_n_iro) < prob_thr : break\n",
    "    if _ > n_top_tweet : break\n",
    "    \n",
    "    hashtag = elem[0].ljust(20)  # Allinea l'hashtag a sinistra con 20 caratteri di spazio\n",
    "    print(f'P({hashtag}|iro=0)\\t= {elem[1]/tot_n_iro:.4f}')\n",
    "\n",
    "    relevant_tweets.add(elem[0])\n",
    "    p_hastg_non_iro[elem[0]] = elem[1]/tot_n_iro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(monti               |iro=1)\t= 0.1661\n",
      "P(labuonascuola       |iro=1)\t= 0.1230\n",
      "P(grillo              |iro=1)\t= 0.0529\n",
      "P(governo             |iro=1)\t= 0.0259\n",
      "P(renzi               |iro=1)\t= 0.0216\n",
      "P(risata              |iro=1)\t= 0.0151\n",
      "P(manovra             |iro=1)\t= 0.0140\n",
      "P(serviziopubblico    |iro=1)\t= 0.0129\n"
     ]
    }
   ],
   "source": [
    "# sorted_hashtags = sorted(tmd_dict[0].items(), key=lambda x: x[1], reverse=True)\n",
    "tot_iro = sum(tmd_dict[1].values())\n",
    "p_hastg_iro = {}\n",
    "\n",
    "for _, elem in enumerate(sorted(tmd_dict[1].items(), key=lambda x: x[1], reverse=True)):\n",
    "    if (elem[1]/tot_iro) < prob_thr : break\n",
    "    if _ > n_top_tweet : break\n",
    "\n",
    "    hashtag = elem[0].ljust(20)  # Allinea l'hashtag a sinistra con 20 caratteri di spazio\n",
    "    print(f'P({hashtag}|iro=1)\\t= {elem[1]/tot_iro:.4f}')\n",
    "    relevant_tweets.add(elem[0])\n",
    "    p_hastg_iro[elem[0]] = elem[1]/tot_iro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labuonascuola', 'manovra', 'risata', 'piazzapulita', 'scuola', 'renzi', 'monti', 'grillo', 'serviziopubblico', 'governo', 'm5s'}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "l è la lista dei tweet con una frequenza maggiuore di .01\n",
    "'''\n",
    "print(relevant_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supponendo ovunque distribuzioni uniformi, questa parte mi servirà poi per fare un confronto.<br>\n",
    "NB questa è una super cazzata, gli hastag non hanno tutti la stessa probabilità di apparire, vediamo se va sufficientemente bene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_iro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tweet = len(tmp_df_hasth) #n. di tweet che contengono gli elem che stiamo tracciando\n",
    "p_iro = tot_iro/n_tweet\n",
    "\n",
    "p = {tweet:(tmd_dict[0][tweet] + tmd_dict[1][tweet])/n_tweet for tweet in relevant_tweets}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labuonascuola': 0.239770279971285,\n",
       " 'manovra': 0.014596793491265853,\n",
       " 'risata': 0.02129696099545346,\n",
       " 'piazzapulita': 0.023689877961234746,\n",
       " 'scuola': 0.0208183776022972,\n",
       " 'renzi': 0.01866475233309404,\n",
       " 'monti': 0.19597989949748743,\n",
       " 'grillo': 0.24168461354391002,\n",
       " 'serviziopubblico': 0.031825795644891124,\n",
       " 'governo': 0.052165589854032066,\n",
       " 'm5s': 0.02273271117492223}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(IRONICO|HASTAG) = |IRONICI CON HASTAG| / |TWEET CON HASTAG|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monti': 0.18803418803418803,\n",
       " 'labuonascuola': 0.11377245508982035,\n",
       " 'grillo': 0.048514851485148516,\n",
       " 'governo': 0.11009174311926606,\n",
       " 'renzi': 0.2564102564102564,\n",
       " 'risata': 0.15730337078651685,\n",
       " 'manovra': 0.21311475409836064,\n",
       " 'serviziopubblico': 0.09022556390977443}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_iro_hastg = {tweet:(tmd_dict[1][tweet])/(tmd_dict[0][tweet] + tmd_dict[1][tweet]) for tweet in p_hastg_iro.keys()}\n",
    "p_iro_hastg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(IRONICO|HASTAG) =  P(HASTG | IRONICO) P(IRONICO) / P(HASTAG)<br>\n",
    "questa cosa poi andrà rimossa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monti': 0.18803418803418806,\n",
       " 'labuonascuola': 0.11377245508982035,\n",
       " 'grillo': 0.048514851485148516,\n",
       " 'governo': 0.11009174311926606,\n",
       " 'renzi': 0.25641025641025644,\n",
       " 'risata': 0.15730337078651685,\n",
       " 'manovra': 0.21311475409836064,\n",
       " 'serviziopubblico': 0.09022556390977443}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_iro_hastg_2 = {tweet: (p_hastg_iro[tweet] * p_iro)/p[tweet] for tweet in p_hastg_iro.keys()}\n",
    "p_iro_hastg_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vediamo quali chiavi sono dove etc...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['monti', 'labuonascuola', 'grillo', 'governo', 'renzi', 'risata', 'manovra', 'serviziopubblico'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hastg_iro.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m5s', 'piazzapulita', 'scuola'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chiavi non iro che non sono nel dict iro\n",
    "set(p_hastg_non_iro.keys())-set(p_hastg_iro.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'manovra', 'renzi'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chiavi iro che non sono nel dict non iro\n",
    "set(p_hastg_iro.keys()) - set(p_hastg_non_iro.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labuonascuola', 'risata', 'monti', 'grillo', 'serviziopubblico', 'governo']\n"
     ]
    }
   ],
   "source": [
    "# chiavi comuni\n",
    "common_keys = list(set(p_hastg_iro.keys()).intersection(set(p_hastg_non_iro.keys())))\n",
    "print(common_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probs delle chiavi in comune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monti': 0.18803418803418803,\n",
       " 'labuonascuola': 0.11377245508982035,\n",
       " 'grillo': 0.048514851485148516,\n",
       " 'governo': 0.11009174311926606,\n",
       " 'renzi': 0.2564102564102564,\n",
       " 'risata': 0.15730337078651685,\n",
       " 'manovra': 0.21311475409836064,\n",
       " 'serviziopubblico': 0.09022556390977443}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_iro_hastg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(iro=1|labuonascuola       )\t= 0.1138\n",
      "P(iro=1|risata              )\t= 0.1573\n",
      "P(iro=1|monti               )\t= 0.1880\n",
      "P(iro=1|grillo              )\t= 0.0485\n",
      "P(iro=1|serviziopubblico    )\t= 0.0902\n",
      "P(iro=1|governo             )\t= 0.1101\n"
     ]
    }
   ],
   "source": [
    "for key in common_keys:\n",
    "    prob = p_iro_hastg[key]\n",
    "    key = key.ljust(20)\n",
    "    print(f'P(iro=1|{key})\\t= {prob:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentuale di tweet del train a cui viene fatto il tratamento: 0.41082642552122584\n"
     ]
    }
   ],
   "source": [
    "tot = tot_n_iro + tot_iro\n",
    "sum = 0\n",
    "for key in common_keys:\n",
    "    sum += p_hastg_iro[key]*tot_iro\n",
    "    sum += p_hastg_non_iro[key]*tot_n_iro\n",
    "print(f'percentuale di tweet del train a cui viene fatto il tratamento: {sum/tot}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
