{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importato package text_enrichment.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from text_enrichment import *\n",
    "\n",
    "seed = 69\n",
    "OUTPUT_PATH = os.path.join(parent_dir, \"2_hashtag_enrichment\", \"output\")\n",
    "PROJ_PATH = \"/home/francesco/Desktop/IRONY/main_22-12/NLP_irony_detector/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_datasets\n",
    "previous_folder = \"1_data_exploration\"\n",
    "train_set, val_set, test_set = load_datasets(os.path.join(parent_dir, previous_folder, \"output\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) preprocessing with placeholders\n",
    "this part allows to do text enrichment considering also placeholders as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) hastag text enrichment\n",
    "finding\n",
    "$$\n",
    "    P(\\text{iro}=1|\\text{feature}) =\n",
    "    \\frac{|\\text{tweets\\_iro\\_with\\_feature}|}\n",
    "    {|\\text{tweets\\_iro\\_with\\_feature}| + |\\text{tweets\\_non\\_iro\\_with\\_feature}|}\n",
    "$$\n",
    "for a more detailed explanation go to text_enrichment/main_text_enrichment.\n",
    "\n",
    "this method does not take into account co occurrences (also dataset is too tiny to implement it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_of_features = find_relevant_features(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the new choosen feature is prob: the idea behind it is to fed it into the classifier part of the model with the desired effect of increase the mean activations of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['prob'] = train_set['text'].apply(lambda x : get_prob_from_sentence(x, prob_of_features))\n",
    "val_set['prob'] = val_set['text'].apply(lambda x : get_prob_from_sentence(x, prob_of_features))\n",
    "test_set['prob'] = test_set['text'].apply(lambda x : get_prob_from_sentence(x, prob_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iro</th>\n",
       "      <th>text</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>1</td>\n",
       "      <td>che ci frega di mario monti, noi abbiamo mario...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>1</td>\n",
       "      <td>Strepitoso il titolo in prima di Libero sul go...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>1</td>\n",
       "      <td>@nataliacavalli Consolati, il governo #Monti h...</td>\n",
       "      <td>0.188034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>1</td>\n",
       "      <td>@SheisCandida beh, beate loro! Io nn possiedo ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>1</td>\n",
       "      <td>Caro #Renzi,se #Grillo spaccava i computer e o...</td>\n",
       "      <td>0.048708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iro                                               text      prob\n",
       "7397    1  che ci frega di mario monti, noi abbiamo mario...  0.000000\n",
       "7398    1  Strepitoso il titolo in prima di Libero sul go...  0.000000\n",
       "7399    1  @nataliacavalli Consolati, il governo #Monti h...  0.188034\n",
       "7400    1  @SheisCandida beh, beate loro! Io nn possiedo ...  0.000000\n",
       "7401    1  Caro #Renzi,se #Grillo spaccava i computer e o...  0.048708"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train_set)\n",
    "val_len = len(val_set)\n",
    "test_len = len(test_set)\n",
    "\n",
    "n_considered_tweets_train  = sum(sum([train_set['prob']!=0]))\n",
    "n_considered_tweets_val  = sum(sum([val_set['prob']!=0]))\n",
    "n_considered_tweets_test  = sum(sum([test_set['prob']!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.27614158335584976\n",
      "val 0.009\n",
      "test 0.004\n"
     ]
    }
   ],
   "source": [
    "print(f\"train {n_considered_tweets_train/train_len}\")\n",
    "print(f\"val {n_considered_tweets_val/val_len}\")\n",
    "print(f\"test {n_considered_tweets_test/test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The considered features in our dataset are unbalanced. to make this algorithm work we choosed to merge and shuffle the tweets of all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not here bec we are using shuffled data!\n",
    "\n",
    "# train_set.to_csv(OUTPUT_PATH+\"train.csv\", index=False)\n",
    "# val_set.to_csv(OUTPUT_PATH+\"val.csv\", index=False)\n",
    "# test_set.to_csv(OUTPUT_PATH+\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) trying to improve the val test percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9402, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train_set, val_set, test_set])\n",
    "dataset.drop(columns='prob', inplace=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iro</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Intanto la partita per Via Nazionale si compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>False illusioni, sgradevoli realtà Mario Monti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>False illusioni, sgradevoli realtà #editoriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iro                                               text\n",
       "0    0  Intanto la partita per Via Nazionale si compli...\n",
       "1    0  False illusioni, sgradevoli realtà Mario Monti...\n",
       "2    0  False illusioni, sgradevoli realtà #editoriale...\n",
       "3    0  Mario Monti: Berlusconi risparmi all'Italia il...\n",
       "4    0  Mario Monti: Berlusconi risparmi all'Italia il..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm keeping the sqme ratio\n",
      "train shape: (7404, 2)\n",
      "val shape: (999, 2)\n",
      "test shape: (999, 2)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(dataset, test_size=0.2125, shuffle=True, random_state=seed)\n",
    "test_set, val_set = train_test_split(test_set, test_size=0.5, shuffle=True, random_state=seed)\n",
    "\n",
    "print(\"I'm keeping the sqme ratio\")\n",
    "print(f\"train shape: {train_set.shape}\")\n",
    "print(f\"val shape: {val_set.shape}\")\n",
    "print(f\"test shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) hastag enfirhment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_of_features = find_relevant_features(train_set)\n",
    "\n",
    "train_set['prob'] = train_set['text'].apply(lambda x : get_prob_from_sentence(x, prob_of_features))\n",
    "val_set['prob'] = val_set['text'].apply(lambda x : get_prob_from_sentence(x, prob_of_features))\n",
    "test_set['prob'] = test_set['text'].apply(lambda x : get_prob_from_sentence(x, prob_of_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iro</th>\n",
       "      <th>text</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0</td>\n",
       "      <td>'Una buona scuola punitiva e non democratica n...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>0</td>\n",
       "      <td>è tutto un gioco di poteri e noi coglioni ad a...</td>\n",
       "      <td>0.096154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>Linee guida 'la buona scuola': cosa prevedono ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>1</td>\n",
       "      <td>Di #Grillo apprezzo la profondità di pensiero ...</td>\n",
       "      <td>0.053218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7371</th>\n",
       "      <td>0</td>\n",
       "      <td>Ma il #palermo dove li mette tutti sti acquisti??</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      iro                                               text      prob\n",
       "823     0  'Una buona scuola punitiva e non democratica n...  0.000000\n",
       "4374    0  è tutto un gioco di poteri e noi coglioni ad a...  0.096154\n",
       "229     0  Linee guida 'la buona scuola': cosa prevedono ...  0.000000\n",
       "4041    1  Di #Grillo apprezzo la profondità di pensiero ...  0.053218\n",
       "7371    0  Ma il #palermo dove li mette tutti sti acquisti??  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1) percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train_set)\n",
    "val_len = len(val_set)\n",
    "test_len = len(test_set)\n",
    "\n",
    "n_considered_tweets_train  = sum(sum([train_set['prob']!=0]))\n",
    "n_considered_tweets_val  = sum(sum([val_set['prob']!=0]))\n",
    "n_considered_tweets_test  = sum(sum([test_set['prob']!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.3117233927606699\n",
      "val 0.3133133133133133\n",
      "test 0.33433433433433435\n"
     ]
    }
   ],
   "source": [
    "print(f\"train {n_considered_tweets_train/train_len}\")\n",
    "print(f\"val {n_considered_tweets_val/val_len}\")\n",
    "print(f\"test {n_considered_tweets_test/test_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_csv(OUTPUT_PATH+ \"/train.csv\", index=False)\n",
    "val_set.to_csv(OUTPUT_PATH + \"/val.csv\", index=False)\n",
    "test_set.to_csv(OUTPUT_PATH + \"/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
